import os
import json
import requests
import re

# ======================================================================
# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ã€AI é…ç½®é¡¹ã€‘
# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  (ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–)
# ======================================================================

OLLAMA_API_BASE = os.environ.get('OLLAMA_API_BASE', "https://ollama.com/api") 
OLLAMA_API_KEY = os.environ.get('OLLAMA_API_KEY') 
OLLAMA_MODEL = os.environ.get('OLLAMA_MODEL', "kimi-k2:1t-cloud") 

if not OLLAMA_API_KEY:
    raise ValueError("ç¯å¢ƒå˜é‡ OLLAMA_API_KEY ç¼ºå¤±ï¼Œè¯·é…ç½® Secret åè¿è¡Œã€‚")

REQUEST_TIMEOUT_SECONDS = 100 
MAX_OUTPUT_TOKENS = 16384

# ã€Prompt æ¨¡æ¿ã€‘ (ä¿æŒä¸å˜)
FULL_PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªDarkroomsçš„æœºå™¨äºº... (æ­¤å¤„çœç•¥ï¼Œä½¿ç”¨æ‚¨çš„å®Œæ•´ Prompt å†…å®¹)
ç”¨æˆ·è¯„è®ºæ˜¯ï¼š'{user_comment}'
"""

# ======================================================================
# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â ã€è¾…åŠ©å‡½æ•°ï¼šæå–é€»è¾‘ã€‘
# ======================================================================

def smart_extract_from_thinking(thinking_text):
    """
    é’ˆå¯¹ GLM/Kimi çš„éæ ‡å‡†è¾“å‡ºè¡Œä¸ºï¼Œä» 'thinking' æ–‡æœ¬ä¸­æå–æ¨¡å‹å›å¤ã€‚
    """
    # 1. å°è¯•æå– <RESPONSE> æ ‡ç­¾ 
    match_tag = re.search(r'<RESPONSE>(.*?)</RESPONSE>', thinking_text, re.DOTALL)
    if match_tag:
        return match_tag.group(1).strip()
    
    # 2. å°è¯•æå– 'å°è¯•X' åçš„å›å¤ 
    match_attempt = re.findall(r'å°è¯•\d+ï¼ˆ.*?ï¼‰ï¼š\s*[\'"]?(.+?)[\'"]?\s*$', thinking_text, re.MULTILINE)
    if match_attempt:
        return match_attempt[-1].strip()
        
    # 3. å¦‚æœä»¥ä¸Šéƒ½å¤±è´¥ï¼Œåˆ™å°è¯•å»é™¤æ˜æ˜¾çš„åˆ†æ/æ€è€ƒå‰ç¼€
    clean_text = re.sub(r'^(.*?(\s*[\d\.]\s*|\s*[a-zA-Z]+\s*)\s*[:ï¼š])', '', thinking_text, count=1, flags=re.MULTILINE).strip()
    
    if len(clean_text) > 20: 
        return clean_text
    
    # 4. å®åœ¨ä¸è¡Œï¼Œè¿”å›æ€è€ƒæ–‡æœ¬çš„å¼€å¤´ä½œä¸ºè­¦å‘Š
    return f"ã€æ€è€ƒå¤±è´¥ï¼Œæ— æ³•æå–å›å¤ã€‘: {thinking_text[:100]}..."

# ======================================================================
# Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â ã€Ollama API è°ƒç”¨ V8ï¼šæœ€ç»ˆä¿®å¤ç‰ˆã€‘
# ======================================================================

def get_glm_response_v8(user_comment):
    """æœ€ç»ˆä¿®å¤ç‰ˆï¼šéæµå¼è¯·æ±‚ï¼Œä¿®å¤è·¯å¾„å’Œ Prompt æ„é€ ï¼Œå¹¶ä¿è¯è¾“å‡ºæ— æ ‡ç­¾ã€‚"""
    
    full_prompt = FULL_PROMPT_TEMPLATE.format(user_comment=user_comment) 
    
    print(f"-> æ­£åœ¨è¿æ¥ Ollama Cloud API: {OLLAMA_API_BASE} (è¶…æ—¶: {REQUEST_TIMEOUT_SECONDS}ç§’, Tokené™åˆ¶: {MAX_OUTPUT_TOKENS})...")
    
    headers = {'Authorization': f'Bearer {OLLAMA_API_KEY}', 'Content-Type': 'application/json'}
    
    payload = {
        'model': OLLAMA_MODEL,
        'messages': [{'role': 'user', 'content': full_prompt}],
        'options': {'temperature': 0.7, 'num_predict': MAX_OUTPUT_TOKENS},
        'stream': False
    }
    
    try:
        response = requests.post(
            f"{OLLAMA_API_BASE}/chat",
            headers=headers,
            json=payload,
            timeout=REQUEST_TIMEOUT_SECONDS
        )
        response.raise_for_status() 

        response_json = response.json()
        
        # æå–é€»è¾‘
        raw_output = response_json.get('message', {}).get('content', '').strip()
        thinking_output = response_json.get('message', {}).get('thinking', '').strip()
        
        if raw_output:
            final_response = raw_output
        elif thinking_output:
            final_response = smart_extract_from_thinking(thinking_output)
        else:
            final_response = "âŒ æ— æ³•è·å–ä»»ä½•å†…å®¹ï¼ˆcontentå’Œthinkingéƒ½ä¸ºç©ºï¼‰ã€‚"

        # -----------------------------------------------------
        # ğŸŒŸ æ–°å¢ï¼šæœ€ç»ˆæ¸…ç†æ­¥éª¤ï¼Œç¡®ä¿ç§»é™¤ <RESPONSE> æ ‡ç­¾
        # -----------------------------------------------------
        if final_response and not final_response.startswith("âŒ"):
            match_tag = re.search(r'<RESPONSE>(.*?)</RESPONSE>', final_response, re.DOTALL | re.IGNORECASE)
            if match_tag:
                # å¦‚æœæ‰¾åˆ°æ ‡ç­¾ï¼Œåˆ™è¿”å›æ ‡ç­¾å†…çš„å†…å®¹
                final_response = match_tag.group(1).strip()
            # å¦åˆ™ï¼Œè¿”å›åŸå§‹å†…å®¹ï¼ˆæ­¤æ—¶ final_response å¯èƒ½æ˜¯ raw_output æˆ– smart_extract_from_thinking çš„ç»“æœï¼‰
        
        return final_response
        
    except Exception as e:
        return f"âŒ Ollama API è°ƒç”¨å¤±è´¥ã€‚é”™è¯¯: {e}"

if __name__ == "__main__":
    print("ã€è­¦å‘Šã€‘ai_service.py é€šå¸¸ä¸åº”ç›´æ¥è¿è¡Œã€‚")
